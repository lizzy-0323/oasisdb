# 设计文档

## 写在前面
目前，有许多专有的向量数据库组件可供用户选择，包括不仅限于以下几种：

- Milvus
- Qdrant
- Pinecone
- Weaviate
- Chroma

其中，milvus 是一个相对发展较好的向量数据库，功能齐全并且社区有好，因此 oasisdb 大量参考了 milvus 的设计。

但不同的是，milvus 实际上是一个分布式向量数据库架构，并且将节点进行了划分，对于初学者而言，实际上会有一定的学习成本。

除了这些以外，还有一些原有的数据库厂商在为已有的数据库提供向量检索的功能，我认为这可能会是未来的趋势，因为对于用户而言，向量检索的时间虽然是需求，但可维护性和简便性也是同样重要，随着 AI 的发展，越来越多的用户会倾向于用更少的组件来搭建系统，从而降低系统的可维护成本，这部分的产品主要有 oceanbase、pgvector, redis-search 等等。

综上所述，为什么还要自己搭建一个向量数据库？ 原因很简单，我想用最简单的架构让初学者快速的了解向量数据库的基本组件，并且不采用任何内在的 rpc 通信，来保证整个系统的绝对轻量级，同时也不提供任何的分布式能力，来保证系统的可维护性。

因此，oasisdb 可以认为是简单的，也可以认为是**不全面**的，但我认为，这恰恰是它的价值。如果你想尝试向量数据库的功能，了解它的原理，self host 一个 rag 系统，那么 oasisdb 就是一个非常好的选择。

## 架构设计

从这张图可以看到整个 oasisdb 的架构![架构设计](./images/architecture.png)

总的来说，可以分为以下几个部分：

1. 网关
2. LRU 缓存
3. 向量存储
4. 标量存储
5. Embedding 服务（可选）

其中，必须的部分就是向量存储和标量存储，我们也可以简单的认为一个单机的向量数据库就是由这两部分组成。

网关这块没什么好说的，主要是提供 restful api，供用户调用。

LRU 缓存，主要是对于一些热门的向量搜索进行缓存，这里的缓存不宜开的过大，否则会占用大量的内存，并且，我们还需要通过（向量，topk）来进行标识，如果某次查询的 topk 更大，那么
就不能用之前缓存的结果进行代替，代码在`internal/cache`目录下。

向量存储，主要是存储向量索引，并进行保存，这里我实现了基于 hnswlib 的 hnsw 索引以及 ivf 索引适用于不同的场景，ivf 索引的精度较低，但对于小量级、高维度的数据来说效果较好，hnsw 则反之， hnsw 索引的代码在`internal/engine`目录下，ivf 索引的代码在`internal/ivf`目录下。

标量存储，这里主要是存储向量的元数据，用一个 kv 存储即可，这里我自己实现了基于 lsm tree 的 kv 存储，代码在`internal/storage`目录下。

Embedding 服务，这里主要是提供向量嵌入的功能，该项为了让用户使用体验更佳，但其实是一个可选项，这里我也仅让它支持了阿里云的向量嵌入服务，代码在`internal/embedding`目录下。

## 技术选型

技术选型上，尽可能的简单，只引入 hnswlib 一个库，其余都是自己实现，为的是对 go 开发者和小白友好，不必要去参考其他库的代码实现，从而增加学习成本。

## 实现细节

这里有几个实现细节是需要注意的：
1. 首先，所有的与磁盘进行操作的部分，都应该采用 WAL（Write-Ahead Logging）机制，以便实现故障恢复，对于向量存储而言，`ApplyOpWithWAL` 函数为所有操作实现了 WAL 机制。除此以外，向量存储还需要添加快照功能，存储的时机，目前可以让用户自己调用，同时也需要添加一个自动快照的机制，并且是否立即写入磁盘，都需要进行配置，这部分还有待完善。

2. 对于标量存储而言，采用比较标准的 LSM tree 结构，可以参考 rocksdb 的实现，LSM tree的优点就是把随机写变为顺序写，大大提升了写入性能，对于向量来说，往往需要一些大批量的写入操作，所以是十分合理的。其中，memtable 架构采用跳表（Skip List）实现，可以参考代码`internal/storage/memtable.go`，如果对 KV 数据库和 LSM tree 感兴趣，可以参考相关的实现，不再赘述。

3. 如何实现过滤查询（filtering）？目前过滤查询还在设计中，常用的有三种方式，pre-filtering、post-filtering、和 in-memory filtering。其中实现难度最高的是 in-memory filtering，需要采用特定的数据结构，在检索中就完成这一过程。pre-filtering则需要先对全量数据进行过滤，再进行向量检索，代价较大，post-filtering则是在检索后进行过滤，但如果用原有的 topk 进行查询，检索后的结果是不够的，所以还需要进一步去更改检索的 topk，这里可以简单改为用户所定义的 topk 的两倍。

